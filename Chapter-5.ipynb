{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## EXAMPLES OF CODES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Definition 5.1\n",
    "\n",
    "A **source code** $C$ for a random variable $X$ is a mapping from $\\mathcal{X}$, the range of $X$, to $D^∗$, the set of finite-length strings of symbols from a D-ary alphabet. Let $C(x)$ denote the codeword corresponding to $x$ and let $l(x)$ denote the length of $C(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Definition 5.2\n",
    "The **expected length** $L(C)$ of a source code $C(x)$ for a random variable $X$ with probability mass function $p(x)$ is given by\n",
    "\n",
    "$$L(c) = \\sum_{x \\in \\mathcal{X}}{}p(x)l(x) $$\n",
    "\n",
    "where $l(x)$ is the length of the codeword associated with $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Definition 5.3\n",
    "A code is said to be **nonsingular** if every element of the range of $X$ maps into a different string in $D^∗$; that is,\n",
    "\n",
    "$$x = x' \\implies C(x) = C(x')$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Definition 5.4\n",
    "\n",
    "The **extension $C^∗$** of a code $C$ is the mapping from finite length strings of $X$ to finite-length strings of $D$, defined by\n",
    "\n",
    "$$ C(x_1x_2...x_n) = C(x_1)C(x_2)...C(x_n) $$\n",
    "where $$C(x_1)C(x_2),...C(x_n)$$ indicates concatenation of the corresponding codewords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Definition 5.5\n",
    "A code is called **uniquely decodable** if its extension is nonsingular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Definition 5.6\n",
    "A code is called a **prefix code** or an **instantaneous code** if no codeword is a prefix of any other codeword."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Classes of Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src = 'Classes_of_Codes.png'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src = 'Classes_of_Codes.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## KRAFT INEQUALITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Theorem 5.1 (Kraft inequality)\n",
    "For any instantaneous code (prefix code) over an alphabet of size $D$, the codeword lengths $l_1, l_2, ... , l_m$ must satisfy the inequality\n",
    "\n",
    "$$ \\sum_{i}{}D^{-l_i} \\leq 1 $$\n",
    "\n",
    "Conversely, given a set of codeword lengths that satisfy this inequality,there exists an instantaneous code with these word lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Theorem 5.2 (Extended Kraft Inequality)\n",
    "For any countably infinite set of codewords that form a prefix code, the codeword lengths satisfy the extended Kraft inequality,\n",
    "\n",
    "$$ \\sum^{\\infty}_{i=1}{D^{-l_i}} \\leq 1 $$\n",
    "\n",
    "Conversely, given any $l_1, l_2, ...$ satisfying the extended Kraft inequality, we can construct a prefix code with these codeword lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## OPTIMAL CODES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "** What is an optimality code?**\n",
    "\n",
    "A code is said to be **optimal**, if it minimizes,\n",
    "\n",
    "$$ L = \\sum{p_il_i}$$\n",
    "\n",
    "over all integers $l_1, l_2, ... , l_m$ satisfying \n",
    "\n",
    "$$\\sum_{i}{D^{-l_i}} \\leq 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Theorem 5.3\n",
    "The expected length $L$ of any instantaneous D-ary code for a random variable $X$ is greater than or equal to the entropy $H_D(X)$; that is\n",
    "\n",
    "$$ L \\geq H_D(X)$$\n",
    "\n",
    "with equality if and only if $D^{-l_i} = p_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Definition 5.7\n",
    "A probability distribution is called **D-adic** if each of the probabilities is equal to $D^{-n}$ for some $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BOUNDS ON OPTIMUM CODE LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Shannon Code\n",
    "\n",
    "$$ l_i = \\big \\lceil  {log_D\\frac{1}{p_i}} \\big  \\rceil $$\n",
    "\n",
    "$$ H_D(X) \\leq L \\leq H_D(X) + 1 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Theorem 5.4 \n",
    "Let $l^∗_1, l^∗_2, . . . , l^∗_m $ be optimal codeword lengths for a source distribution $\\mathbf{p}$ and a D-ary alphabet, and let $L^∗$ be the associated expected length of an optimal code ($L^∗ = \\sum_{i}{p_il^∗_i}$ ). Then\n",
    "\n",
    "$$ H_D(X) \\leq L^* < H_D(X) + 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Extended Definition of Expected Length\n",
    "Now consider a system in which we send a sequence of $n$ symbols from $X$. The symbols are assumed to be drawn i.i.d. according to $p(x)$. We can consider these $n$ symbols to be a supersymbol from the alphabet $\\mathcal{X}^n$.\n",
    "\n",
    "Define $L_n$ to be the expected codeword length per input symbol, that is, if $l(x_1, x_2, ... , x_n)$ is the length of the binary codeword associated with $(x_1, x_2, ... , x_n)$\n",
    "\n",
    "$$L_n = \\frac{1}{n} \\sum{p(x_1,x_2, ... , x_n)l(x_1,x_2, ... , x_n) = \\frac{1}{n} E\\{ l(x_1,x_2, ... , x_n)\\}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Theorem 5.5\n",
    "\n",
    "The minimum expected codeword length per symbol satisfies\n",
    "\n",
    "$$ \\frac{H(X_1,X_2, ... X_n)}{n} \\leq L^{*}_{n} < \\frac{H(X_1,X_2, ... X_n)}{n} + \\frac{1}{n}$$\n",
    "\n",
    "Moreover, if $X_1,X_2, ... X_n$ is a stationary stochastic process,\n",
    "\n",
    "$$L^{*}_{n} \\to H(\\mathcal{X}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Theorem 5.6\n",
    "\n",
    "The expected length under $p(x)$ of the code assignment $l(x) = \\lceil log \\frac{1}{q(x)} \\rceil$satisfies\n",
    "\n",
    "$$ H(p) + D(p \\ || \\ q) \\leq E_p\\{l(x)\\} = \\sum_{x}{p(x)l(x)} < H(p) + D(p \\ || \\ q) + 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## KRAFT INEQUALITY FOR UNIQUELY DECODABLE CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Theorem 5.7 (McMillan)\n",
    "The codeword lengths of any uniquely decodable D-ary code must satisfy the Kraft inequality\n",
    "\n",
    "$$ \\sum_{i}{D^{-l_i}} \\leq 1 $$\n",
    "Conversely, given a set of codeword lengths that satisfy this inequality, it is possible to construct a uniquely decodable code with these codeword lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Corollary\n",
    "A uniquely decodable code for an infinite source alphabet $\\mathcal{X}$\n",
    "also satisfies the Kraft inequality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## HUFFMAN CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Definition 5.8\n",
    "\n",
    "Let $\\mathcal{X}$ be a set od $m$ source symbols, let $D$ be a D-ary alphabet. A Huffman code $C_{Huff}: \\mathcal{X} \\to D^*$ is an optimum instantaneous code in which the $2+((m-2)mod(D-1))$ least likely source symbols have same length and differ only in last digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src = 'Huffman.png'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src = 'Huffman.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SOME COMMENTS ON HUFFMAN CODES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 1. Equivalence of source coding and 20 questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src = 'akinator.png'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src = 'akinator.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2. Huffman coding for weighted codewords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 3. Huffman coding and \"slice\" question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 4. Huffman codes and Shannon codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 5. Fano codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## OPTIMALITY OF HUFFMAN CODES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Lemma 5.8\n",
    "For any distribution, there exists an optimal instantaneous code (with minimum expected length) that satisfies the following properties:\n",
    "\n",
    "1. The lengths are ordered inversely with the probabilities (i.e., if $p_j > p_k$, then $l_j ≤ l_k$).\n",
    "\n",
    "2. The two longest codewords have the same length.\n",
    "\n",
    "3. Two of the longest codewords differ only in the last bit and correspond to the two least likely symbols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Illustration:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "%%html\n",
    "<img src = 'lemma.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Definition 5.9\n",
    "The optimal code which satisfy the properties of the *lemma 5.8* is called **canonical codes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Theorem 5.9\n",
    "Huffman coding is optimal; that is, if $C^∗$ is a Huffman code and $C'$ is any other uniquely decodable code, $L(C^∗) ≤ L(C')$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Illustartion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src = 'huffman2.png'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src = 'huffman2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SHANNON-FANO-ELIAS CODING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Construction:\n",
    "\n",
    "1. Without loss of generality, we can take $X = \\{1, 2, . . .,m\\}$. Assume that $p(x) > 0$ for all $x$. The cumulative distribution function $F(x)$ is defined as $$ F(x) = \\sum_{a \\leq x}{p(a)} $$ \n",
    "\n",
    "2. Next we define the modified cumulative distribution function  $$ \\overline{F}(x) = \\sum_{a < x}{p(a)} + \\frac{p(x)}{2}$$                                                                                            where $\\overline{F}(x)$ denotes the sum of the probabilities of all symbols less than $x$ plus half the probability of the symbol x.\n",
    "\n",
    "3. $\\overline{F}(x)$ is a real number expressible only by an infinite number of bits. We truncate $\\overline{F}(x)$ to $l(x)$ bits (denoted by $\\lfloor \\overline{F}(x)\\rfloor_{l(x)}$). Thus, we use the first $l(x)$ bits of $\\overline{F}(x)$ as a code for $x$. Here, $$ l(x) = \\big \\lceil  {log_{2}\\frac{1}{p(x)}} \\big  \\rceil + 1$$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Illustration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src = 'shanno-fano-elias.png'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src = 'shanno-fano-elias.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src = 'sfe.png'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src = 'sfe.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Properties:\n",
    "\n",
    "1. **Prefix Free Condition:** If we consider each code word $z_1z_2...z_l$ is representing not a point but an interval $[0.z_1z_2...z_l, \\  0.z_1z_2...z_l+\\frac{1}{2^{l(x)}})$. Then the code is prefix free if and only if the intervals corresponding to codewords are disjoint.\n",
    "\n",
    "2. **Upper Bound of Expected length:** $$L(x) < H(X) + 2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## COMPETETIVE OPTIMALITY OF SHANNON CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Definition 5.10\n",
    "\n",
    "Code A **competitively dominates** code B if\n",
    "\n",
    "$$ \\mathbf{Pr}\\{l_A(X) < l_B(X)\\} \\geq  \\mathbf{Pr}\\{l_A(X) > l_B(X)\\} $$\n",
    "\n",
    "Furthermore, if code A competitively dominates all other uniquely decodable codes, then code A is said to be **competitively optimal**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Theorem 5.10\n",
    "Let $l(x) = \\big \\lceil  {log_{2}\\frac{1}{p(x)}} \\big  \\rceil + 1$  be the codeword lengths associated with the Shannon code, and let $l'(x)$ be the codeword lengths associated with any other uniquely decodable code. Then\n",
    "\n",
    "$$ \\mathbf{Pr}( \\ l(x) \\geq l'(x) + c \\ ) \\leq \\frac{1}{2^{c-1}} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Theorem 5.11\n",
    "For a dyadic probability mass function $p(x)$, let $l(x) = log_{2}\\frac{1}{p(x)}$ be the word lengths of the binary Shannon code for the source, and let $l'(x)$ be the lengths of any other uniquely decodable binary code for the source. Then\n",
    "\n",
    "$$ \\mathbf{Pr}\\{l(X) < l'(X)\\} \\geq  \\mathbf{Pr}\\{l(X) > l'(X)\\} $$\n",
    "\n",
    "with equality if and only if $l'(x) = l(x)$ for all $x$. Thus, the code length assignment $l(x) = log_2\\frac{1}{p(x)}$ is uniquely competitively optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Corollary:\n",
    "For nondyadic probability mass functions,\n",
    "\n",
    "$$ E\\{ \\ sgn( \\ l(X) - l('X) - 1 \\} \\leq 0 $$\n",
    "\n",
    "where, $l(x) = \\big \\lceil  {log_{2}\\frac{1}{p(x)}} \\big  \\rceil$ and $l'(x)$ is any other uniquely decodable code for the source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## GENERATION OF DISCRETE DISTRIBUTION FROM FAIR COINS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Problem Statement:\n",
    "\n",
    "We are given a sequence of fair coin tosses $Z_1,Z_2, . . . $, and we wish to generate a discrete random variable $X \\in X = \\{1, 2, . . . , m\\}$ with probability mass function $ \\mathbf{p} = (p_1, p_2, . . . , p_m)$. Let the random variable $T$ denote the number of coin flips used in the algorithm.\n",
    "\n",
    "We can describe the algorithm mapping strings of bits $Z_1,Z_2, . . . $, to possible outcomes $X$ by a binary tree. The leaves of the tree are marked by output symbols $X$, and the path to the leaves is given by the sequence of bits produced by the fair coin.\n",
    "\n",
    "* How many fair coin flips does it take to generate a random variable $X$ drawn according to the probability mass function $\\mathbf{p}$?\n",
    "\n",
    "* What is the most efficient algorithm to generate a given distribution, and how is this related to the entropy of the distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Properties of Tree Representing this Algorithm:\n",
    "The tree representing the algorithm must satisfy certain properties:\n",
    "\n",
    "1. The tree should be complete (i.e., every node is either a leaf or has two descendants in the tree). The tree may be infinite, as we will see in some examples.\n",
    "\n",
    "2. The probability of a leaf at depth $k$ is $2^{−k}$. Many leaves may be labeled with the same output symbol—the total probability of all these leaves should equal the desired probability of the output symbol.\n",
    "\n",
    "3. The expected number of fair bits $E(T)$ required to generate $X$ is equal to the expected depth of this tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Lemma 5.12\n",
    "For any complete tree, consider a probability distribution on the leaves such that the probability of a leaf at depth $k$ is $2^{−k}$. Then the expected depth of the tree is equal to the entropy of this distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Theorem 5.13\n",
    "For any algorithm generating $X$, the expected number of fair bits used is greater than the entropy $H(X)$, that is,\n",
    "\n",
    "$$ E(T) \\geq H(X) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Theorem 5.14\n",
    "Let the random variable $X$ have a dyadic distribution. The optimal algorithm to generate $X$ from fair coin flips requires an expected number of coin tosses precisely equal to the entropy:\n",
    "\n",
    "$$ E(T) = H(X) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src = 'binary.png' width=\"500\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src = 'binary.png' width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Theorem 5.14\n",
    "\n",
    "The expected number of fair bits required by the optimal algorithm to generate a random variable $X$ lies between $H(X)$ and $H(X) + 2$:\n",
    "\n",
    "$$ H(X) \\leq E(T) < H(X) + 2 $$ "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
